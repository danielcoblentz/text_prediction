{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import data preprocessing libraries\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# load data\n",
    "file = open('/True.txt', 'r', encoding='utf8')\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "file.close()\n",
    "\n",
    "data =''\n",
    "for i in lines:\n",
    "    data = ' '.join(lines)\n",
    "\n",
    "# clean data remove any unwanted chars\n",
    "data = re.sub(r'[^\\w\\s]', '', data.strip().lower())\n",
    "print(data[:10])\n",
    "\n",
    "# tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "pickle.dump(tokenizer, open('/content/drive/MyDrive/Colab Notebooks/tokenizer1.pkl', 'wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "print(sequence_data[:10])\n",
    "\n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "# create sequences\n",
    "sequence = []\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequence.append(words)\n",
    "\n",
    "# divide the data into features (X) and labels (Y)\n",
    "x = []\n",
    "y = []\n",
    "for i in sequence:\n",
    "    x.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = to_categorical(y, num_classes=vocabulary_size)\n",
    "\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocabulary_size, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile and train the model\n",
    "checkPoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/True_model.keras',\n",
    "                             monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(x, y, epochs=50, batch_size=64, callbacks=[checkPoint])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
